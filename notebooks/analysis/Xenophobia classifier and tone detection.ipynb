{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # remove links\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from alive_progress import alive_bar\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Xenophobia classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Hate Speech words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_cleaning(word_list): \n",
    "    word_list = [x for x in word_list if str(x) != 'nan'] #remove nan\n",
    "    word_list = [x.lower() for x in word_list] #to lowercase\n",
    "    word_list_noaccent = [unidecode.unidecode(x) for x in word_list] #remove accents\n",
    "    word_list = word_list +  word_list_noaccent #add the list without accents to the original list\n",
    "    word_list = list(dict.fromkeys(word_list)) #remove duplicates\n",
    "\n",
    "    return(word_list)\n",
    "\n",
    "col_insults = pd.read_excel('./../../../Scripts VMASC/Social Network Inform Files/insultos_colombiamagica_gender.xlsx')\n",
    "\n",
    "men_insults = col_insults['insults_man'].tolist() + col_insults['insults_men'].tolist()\n",
    "women_insults = col_insults['insults_woman'].tolist() + col_insults['insults_women'].tolist()\n",
    "nogender_insults = col_insults['insults_no_gender'].tolist() + col_insults['insults_no_gender_plural'].tolist()\n",
    "\n",
    "#Removing the terms veneco, venecos, veneca and venecas for just taking to account the insults to venezuelans\n",
    "men_insults.remove('Veneco')\n",
    "men_insults.remove('Venecos')\n",
    "women_insults.remove('Veneca')\n",
    "women_insults.remove('Venecas')\n",
    "\n",
    "#Include the original version (Upper case) of the insults and the lowercase version\n",
    "men_insults = men_insults + list_cleaning(men_insults)\n",
    "women_insults = list_cleaning(women_insults)\n",
    "nogender_insults = list_cleaning(nogender_insults)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions pre-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HS or not HS classify function\n",
    "def xenophobia_classify_gender(data, men_comp_vect, women_comp_vect, nongender_comp_vect, colname = 'text'):\n",
    "    \n",
    "    total_insults_men = []\n",
    "    total_insults_women = []\n",
    "    total_insults_nogender = []\n",
    "    total_insults = []\n",
    "    HS = []\n",
    "    HS_men = []\n",
    "    HS_women = []\n",
    "    with alive_bar(len(data), force_tty = True) as bar: \n",
    "        for text in data['text']:\n",
    "            splitted_text = text.split()\n",
    "            n_insults_men = 0; n_insults_women = 0; n_insults_nogender = 0\n",
    "            for word in splitted_text:\n",
    "                if word in men_comp_vect: n_insults_men += 1\n",
    "                if word in women_comp_vect: n_insults_women += 1 \n",
    "                if word in nongender_comp_vect: n_insults_nogender += 1 \n",
    "            total_insults_men.append(n_insults_men)\n",
    "            total_insults_women.append(n_insults_women)\n",
    "            total_insults_nogender.append(n_insults_nogender)\n",
    "            \n",
    "            n_insults = n_insults_men+n_insults_women+n_insults_nogender\n",
    "            total_insults.append(n_insults)\n",
    "            \n",
    "            HS_i = 0; HS_men_i = 0; HS_women_i= 0\n",
    "            if n_insults>0: HS_i= 1\n",
    "            if n_insults_men > n_insults_women:\n",
    "                HS_men_i = 1\n",
    "            elif n_insults_men < n_insults_women:\n",
    "                HS_women_i = 1\n",
    "            \n",
    "            HS.append(HS_i)\n",
    "            HS_men.append(HS_men_i)\n",
    "            HS_women.append(HS_women_i)\n",
    "            bar()\n",
    "    data['n_insults_men'] = total_insults_men\n",
    "    data['n_insults_women'] = total_insults_women\n",
    "    data['n_insults_nogender'] = total_insults_nogender\n",
    "    data['total_insults'] = total_insults\n",
    "    data['HS'] = HS\n",
    "    data['HS_men'] = HS_men\n",
    "    data['HS_women'] = HS_women\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic analysis function\n",
    "def xenophobia_analysis_gender(dataframe, output = 'summary'):\n",
    "    import statistics\n",
    "    import pandas as pd\n",
    "    total = sum(dataframe['total_insults'])\n",
    "    men = sum(dataframe['n_insults_men'])\n",
    "    prop_men = round(100*men/total,3)\n",
    "    women = sum(dataframe['n_insults_women'])\n",
    "    prop_women = round(100*women/total,3)\n",
    "    nogender = sum(dataframe['n_insults_nogender'])\n",
    "    prop_nogender = round(100*nogender/total,3)\n",
    "\n",
    "    if output == 'summary':\n",
    "        print('Total insults in tweets: ', total, sep = \"\")\n",
    "        print('Total male insults in tweets:', men, \" (\",prop_men ,\" %)\", sep = \"\")\n",
    "        print('Total female insults in tweets:', women, \" (\",prop_women ,\" %)\", sep = \"\")\n",
    "        print('Total nogender insults in tweets:', nogender, \" (\",prop_nogender ,\" %)\", sep = \"\")\n",
    "        print('Total HS tweets:', sum(dataframe['HS']))\n",
    "        print('Mean of HS tweets:', 100*statistics.mean(dataframe['HS']),'%')\n",
    "\n",
    "    elif output == 'dataframe':\n",
    "        df = [{'n_total_insults':total, 'n_men_insults':men, 'n_women_insults':women, 'n_nogender_insults':nogender,\n",
    "         'prop_men_insults':prop_men, 'prop_women_insults':prop_women, 'prop_nogender_insults':prop_nogender}]\n",
    "        return(pd.DataFrame.from_dict(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the cleaned tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (see Social Network Data Extraction and Combining.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data0 = pd.read_csv('./../data/texts/colombian_valid_tweets.csv')\n",
    "tweets_data0['text'] = tweets_data0['text'].astype(str).apply(lambda x: x.lower())\n",
    "\n",
    "#cleaning\n",
    "# 1. Links\n",
    "def link_removal (string):\n",
    "    return(re.sub('http[s]?://\\S+', '', string))\n",
    "tweets_data0['text'] = tweets_data0['text'].apply(link_removal)\n",
    "\n",
    "# 2. mentions\n",
    "def mention_removal (string):\n",
    "    return(re.sub('@\\S+', '', string))\n",
    "tweets_data0['text'] = tweets_data0['text'].apply(mention_removal)\n",
    "\n",
    "# 3. stop words\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "def remove_stopwords (string):\n",
    "    words = string.strip()\n",
    "    words = [w for w in words if not w.lower() in stop_words]\n",
    "    return(' '.join(words))\n",
    "tweets_data0['text_clean'] = tweets_data0['text'].apply(mention_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 1664903/1664903 [100%] in 3:23.5 (8181.63/s)                                  ▇▇▅ 150134/1664903 [9%] in 16s (9125.8/s, eta: 2:46)  ▁▃▅ 210350/1664903 [13%] in 24s (8687.6/s, eta: 2:48)  ▆▄▂ 581572/1664903 [35%] in 1:13 (8009.2/s, eta: 2:15)  ▂▄▆ 996355/1664903 [60%] in 2:04 (8044.8/s, eta: 1:23)  ▅▇▇ 1326247/1664903 [80%] in 2:44 (8097.2/s, eta: 42s)  ▇▇▅ 1519610/1664903 [91%] in 3:06 (8166.3/s, eta: 18s) \n"
     ]
    }
   ],
   "source": [
    "result_data = xenophobia_classify_gender(tweets_data0, men_insults, women_insults, nogender_insults, colname = 'text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insults in tweets: 60636\n",
      "Total male insults in tweets:28185 (46.482 %)\n",
      "Total female insults in tweets:13795 (22.751 %)\n",
      "Total nogender insults in tweets:18656 (30.767 %)\n",
      "Total HS tweets: 53934\n",
      "Mean of HS tweets: 3.2394680050429363 %\n"
     ]
    }
   ],
   "source": [
    "xenophobia_analysis_gender(result_data, output='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech proportion by year\n",
    "xenophobia_results_year = result_data.groupby(result_data['date'].map(lambda x: x[0:4])).mean() #result_data['referred_to']\n",
    "# Hate speech proportion by month\n",
    "xenophobia_results_month = result_data.groupby(result_data['date'].map(lambda x: x[0:7])).mean() #result_data['referred_to']\n",
    "\n",
    "with pd.ExcelWriter('./../analysis/xenophobia_results.xlsx') as writer:\n",
    "    xenophobia_results_year.to_excel(writer, sheet_name= 'year')\n",
    "    xenophobia_results_month.to_excel(writer, sheet_name= 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech count by year\n",
    "xenophobia_counts_year = result_data.groupby(result_data['date'].map(lambda x: x[0:4])).sum() #result_data['referred_to']\n",
    "# Hate speech counts by month\n",
    "xenophobia_counts_month = result_data.groupby(result_data['date'].map(lambda x: x[0:7])).sum() #result_data['referred_to']\n",
    "\n",
    "path = './../analysis/xenophobia_results.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_counts_year.to_excel(writer, sheet_name= 'counts - year')\n",
    "    xenophobia_counts_month.to_excel(writer, sheet_name= 'counts - month')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for only the tweets with veneco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the texts that do not contain 'veneco'\n",
    "tweets_with_veneco = tweets_data0[tweets_data0['text'].str.contains('veneco')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 560089/560089 [100%] in 1:06.3 (8443.54/s)                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_men'] = total_insults_men\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_women'] = total_insults_women\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_nogender'] = total_insults_nogender\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['total_insults'] = total_insults\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS'] = HS\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS_men'] = HS_men\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS_women'] = HS_women\n"
     ]
    }
   ],
   "source": [
    "result_data_veneco = xenophobia_classify_gender(tweets_with_veneco, men_insults, women_insults, nogender_insults, colname = 'text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insults in tweets: 45813\n",
      "Total male insults in tweets:22325 (48.731 %)\n",
      "Total female insults in tweets:8547 (18.656 %)\n",
      "Total nogender insults in tweets:14941 (32.613 %)\n",
      "Total HS tweets: 40450\n",
      "Mean of HS tweets: 7.22206649300379 %\n"
     ]
    }
   ],
   "source": [
    "xenophobia_analysis_gender(result_data_veneco, output='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech proportion by year\n",
    "xenophobia_results_year_veneco = result_data_veneco.groupby(result_data_veneco['date'].map(lambda x: x[0:4])).mean() #result_data['referred_to']\n",
    "# Hate speech proportion by month\n",
    "xenophobia_results_month_veneco = result_data_veneco.groupby(result_data_veneco['date'].map(lambda x: x[0:7])).mean() #result_data['referred_to']\n",
    "\n",
    "\n",
    "path = './../analysis/xenophobia_results.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_results_year_veneco.to_excel(writer, sheet_name= 'year - veneco')\n",
    "    xenophobia_results_month_veneco.to_excel(writer, sheet_name= 'month - veneco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech count by year\n",
    "xenophobia_counts_year_veneco = result_data_veneco.groupby(result_data_veneco['date'].map(lambda x: x[0:4])).sum() #result_data['referred_to']\n",
    "# Hate speech counts by month\n",
    "xenophobia_counts_month_veneco = result_data_veneco.groupby(result_data_veneco['date'].map(lambda x: x[0:7])).sum() #result_data['referred_to']\n",
    "\n",
    "path = './../analysis/xenophobia_results.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_counts_year_veneco.to_excel(writer, sheet_name= 'year counts - veneco')\n",
    "    xenophobia_counts_month_veneco.to_excel(writer, sheet_name= 'month counts - veneco')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for only the tweets with veneca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the texts that do not contain 'veneca'\n",
    "tweets_with_veneca = tweets_data0[tweets_data0['text'].str.contains('veneca')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 157057/157057 [100%] in 15.4s (10205.06/s)                                   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_men'] = total_insults_men\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_women'] = total_insults_women\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['n_insults_nogender'] = total_insults_nogender\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['total_insults'] = total_insults\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS'] = HS\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS_men'] = HS_men\n",
      "C:\\Users\\jmart130\\AppData\\Local\\Temp\\ipykernel_9472\\501867129.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['HS_women'] = HS_women\n"
     ]
    }
   ],
   "source": [
    "result_data_veneca = xenophobia_classify_gender(tweets_with_veneca, men_insults, women_insults, nogender_insults, colname = 'text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insults in tweets: 7448\n",
      "Total male insults in tweets:1703 (22.865 %)\n",
      "Total female insults in tweets:4232 (56.821 %)\n",
      "Total nogender insults in tweets:1513 (20.314 %)\n",
      "Total HS tweets: 6642\n",
      "Mean of HS tweets: 4.229037865233641 %\n"
     ]
    }
   ],
   "source": [
    "xenophobia_analysis_gender(result_data_veneca, output='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech proportion by year\n",
    "xenophobia_results_year_veneca = result_data_veneca.groupby(result_data_veneca['date'].map(lambda x: x[0:4])).mean() #result_data['referred_to']\n",
    "# Hate speech proportion by month\n",
    "xenophobia_results_month_veneca = result_data_veneca.groupby(result_data_veneca['date'].map(lambda x: x[0:7])).mean() #result_data['referred_to']\n",
    "\n",
    "\n",
    "path = './../analysis/xenophobia_results.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_results_year_veneca.to_excel(writer, sheet_name= 'year - veneca')\n",
    "    xenophobia_results_month_veneca.to_excel(writer, sheet_name= 'month - veneca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hate speech count by year\n",
    "xenophobia_counts_year_veneca = result_data_veneca.groupby(result_data_veneca['date'].map(lambda x: x[0:4])).sum() #result_data['referred_to']\n",
    "# Hate speech counts by month\n",
    "xenophobia_counts_month_veneca = result_data_veneca.groupby(result_data_veneca['date'].map(lambda x: x[0:7])).sum() #result_data['referred_to']\n",
    "\n",
    "path = './../analysis/xenophobia_results.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_counts_year_veneca.to_excel(writer, sheet_name= 'year counts - veneca')\n",
    "    xenophobia_counts_month_veneca.to_excel(writer, sheet_name= 'month counts - veneca')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hate speech counts 2020-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result_data\n",
    "df = df[(df['date'] >= '2020-03-01') & (df['date'] <= '2020-03-31')]\n",
    "xenophobia_counts_2020_03 = df.groupby([df['referred_to'],df['date']]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "path = './../analysis/xenophobia_results_divided.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    xenophobia_counts_2020_03.to_excel(writer, sheet_name= 'counts - 2020-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './../analysis/xenophobia_results_divided.xlsx'\n",
    "book = load_workbook(path)\n",
    "\n",
    "with pd.ExcelWriter(path, engine = 'openpyxl') as writer:\n",
    "    writer.book = book\n",
    "    df.to_excel(writer, sheet_name= '2020-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joseph\\anaconda3\\lib\\site-packages\\pyjsonviewer\\pyjsonviewer.py start!!\n"
     ]
    }
   ],
   "source": [
    "#!pyjsonviewer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the VMASC MSVSCC 2023 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # remove links\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from alive_progress import alive_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Xenophobia classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Hate Speech words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_cleaning(word_list): \n",
    "    word_list = [x for x in word_list if str(x) != 'nan']\n",
    "    word_list = [x.lower() for x in word_list] #to lowercase\n",
    "    word_list_noaccent = [unidecode.unidecode(x) for x in word_list] \n",
    "    word_list = word_list +  word_list_noaccent\n",
    "    \n",
    "    hs_words = []\n",
    "    [hs_words.append(x) for x in col_insults if x not in hs_words]\n",
    "    return(word_list)\n",
    "\n",
    "col_insults = pd.read_csv('./../../Social Network Inform Files/insultos_colombiamagica_gender.csv', encoding='iso-8859-1', sep = ';')\n",
    "\n",
    "men_insults = col_insults['insults_man'].tolist() + col_insults['insults_men'].tolist()\n",
    "women_insults = col_insults['insults_woman'].tolist() + col_insults['insults_women'].tolist()\n",
    "nogender_insults = col_insults['insults_no_gender'].tolist() + col_insults['insults_no_gender_plural'].tolist()\n",
    "\n",
    "# men_insults = list_cleaning(men_insults)\n",
    "# women_insults = list_cleaning(women_insults)\n",
    "# nogender_insults = list_cleaning(nogender_insults)\n",
    "men_insults = ['veneco']\n",
    "women_insults = ['veneca']\n",
    "nogender_insults = list_cleaning(['venecos', 'venecas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions pre-reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HS or not HS classify function\n",
    "def xenophobia_classify_gender(data, men_comp_vect, women_comp_vect, nongender_comp_vect, colname = 'text'):\n",
    "    \n",
    "    total_insults_men = []\n",
    "    total_insults_women = []\n",
    "    total_insults_nogender = []\n",
    "    total_insults = []\n",
    "    HS = []\n",
    "    HS_men = []\n",
    "    HS_women = []\n",
    "    with alive_bar(len(data), force_tty = True) as bar: \n",
    "        for text in data['text']:\n",
    "            splitted_text = text.split()\n",
    "            n_insults_men = 0; n_insults_women = 0; n_insults_nogender = 0\n",
    "            for word in splitted_text:\n",
    "                if word in men_comp_vect: n_insults_men += 1\n",
    "                if word in women_comp_vect: n_insults_women += 1 \n",
    "                if word in nongender_comp_vect: n_insults_nogender += 1 \n",
    "            total_insults_men.append(n_insults_men)\n",
    "            total_insults_women.append(n_insults_women)\n",
    "            total_insults_nogender.append(n_insults_nogender)\n",
    "            \n",
    "            n_insults = n_insults_men+n_insults_women+n_insults_nogender\n",
    "            total_insults.append(n_insults)\n",
    "            \n",
    "            HS_i = 0; HS_men_i = 0; HS_women_i= 0\n",
    "            if n_insults>0: HS_i= 1\n",
    "            if n_insults_men > n_insults_women:\n",
    "                HS_men_i = 1\n",
    "            elif n_insults_men < n_insults_women:\n",
    "                HS_women_i = 1\n",
    "            \n",
    "            HS.append(HS_i)\n",
    "            HS_men.append(HS_men_i)\n",
    "            HS_women.append(HS_women_i)\n",
    "            bar()\n",
    "    data['n_insults_men'] = total_insults_men\n",
    "    data['n_insults_women'] = total_insults_women\n",
    "    data['n_insults_nogender'] = total_insults_nogender\n",
    "    data['total_insults'] = total_insults\n",
    "    data['HS'] = HS\n",
    "    data['HS_men'] = HS_men\n",
    "    data['HS_women'] = HS_women\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistic analysis function\n",
    "def xenophobia_analysis_gender(dataframe, output = 'summary'):\n",
    "    import statistics\n",
    "    import pandas as pd\n",
    "    total = sum(dataframe['total_insults'])\n",
    "    men = sum(dataframe['n_insults_men'])\n",
    "    prop_men = round(100*men/total,3)\n",
    "    women = sum(dataframe['n_insults_women'])\n",
    "    prop_women = round(100*women/total,3)\n",
    "    nogender = sum(dataframe['n_insults_nogender'])\n",
    "    prop_nogender = round(100*nogender/total,3)\n",
    "\n",
    "    if output == 'summary':\n",
    "        print('Total insults in tweets: ', total, sep = \"\")\n",
    "        print('Total male insults in tweets:', men, \" (\",prop_men ,\" %)\", sep = \"\")\n",
    "        print('Total female insults in tweets:', women, \" (\",prop_women ,\" %)\", sep = \"\")\n",
    "        print('Total nogender insults in tweets:', nogender, \" (\",prop_nogender ,\" %)\", sep = \"\")\n",
    "        print('Total HS tweets:', sum(dataframe['HS']))\n",
    "        print('Mean of HS tweets:', 100*statistics.mean(dataframe['HS']),'%')\n",
    "\n",
    "    elif output == 'dataframe':\n",
    "        df = [{'n_total_insults':total, 'n_men_insults':men, 'n_women_insults':women, 'n_nogender_insults':nogender,\n",
    "         'prop_men_insults':prop_men, 'prop_women_insults':prop_women, 'prop_nogender_insults':prop_nogender}]\n",
    "        return(pd.DataFrame.from_dict(df))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the cleaned tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (see Social Network Data Extraction and Combining.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data0 = pd.read_csv('./../data/texts/colombian_valid_tweets.csv')\n",
    "tweets_data0['text'] = tweets_data0['text'].astype(str).apply(lambda x: x.lower())\n",
    "\n",
    "#cleaning\n",
    "# 1. Links\n",
    "def link_removal (string):\n",
    "    return(re.sub('http[s]?://\\S+', '', string))\n",
    "tweets_data0['text'] = tweets_data0['text'].apply(link_removal)\n",
    "\n",
    "# 2. mentions\n",
    "def mention_removal (string):\n",
    "    return(re.sub('@\\S+', '', string))\n",
    "tweets_data0['text'] = tweets_data0['text'].apply(mention_removal)\n",
    "\n",
    "# 3. stop words\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "def remove_stopwords (string):\n",
    "    words = string.strip()\n",
    "    words = [w for w in words if not w.lower() in stop_words]\n",
    "    return(' '.join(words))\n",
    "tweets_data0['text_clean'] = tweets_data0['text'].apply(mention_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 1664903/1664903 [100%] in 11.2s (148119.98/s)                                 ▁▃▅ 741708/1664903 [45%] in 5s (153026.8/s, eta: 6s) \n"
     ]
    }
   ],
   "source": [
    "result_data = xenophobia_classify_gender(tweets_data0, men_insults, women_insults, nogender_insults, colname = 'text_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total insults in tweets: 614810\n",
      "Total male insults in tweets:247465 (40.251 %)\n",
      "Total female insults in tweets:104335 (16.97 %)\n",
      "Total nogender insults in tweets:263010 (42.779 %)\n",
      "Total HS tweets: 581930\n",
      "Mean of HS tweets: 34.95278703924493 %\n"
     ]
    }
   ],
   "source": [
    "xenophobia_analysis_gender(result_data, output='summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hate speech proportion by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenophobia_results_year = result_data.groupby(result_data['date'].map(lambda x: x[0:4])).mean() #result_data['referred_to']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hate speech proportion by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xenophobia_results_month = result_data.groupby(result_data['date'].map(lambda x: x[0:7])).mean() #result_data['referred_to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('./../analysis/xenophobia_results_divided[VMASC CONFERENCE].xlsx') as writer:\n",
    "    xenophobia_results_year.to_excel(writer, sheet_name= 'year')\n",
    "    xenophobia_results_month.to_excel(writer, sheet_name= 'month')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4c72cb86a1db53a01b4668f2d4d3b8bfc875dfc5277ab14e6ce4b5493eba8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
