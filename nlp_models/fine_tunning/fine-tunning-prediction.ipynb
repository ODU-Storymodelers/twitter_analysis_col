{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions - subject model ⚠ Use Python 3.9.13 64-bit kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joseph\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer)\n",
    "from alive_progress import alive_bar\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "model_tunned = AutoModelForSequenceClassification.from_pretrained(\"./model2_subject/bert_wwm/\", num_labels=4)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'migrants', 'score': 0.9996597766876221}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model_tunned, tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"veneco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664903\n"
     ]
    }
   ],
   "source": [
    "y_in = pd.read_csv('./../data/texts/colombian_valid_tweets.csv')\n",
    "print(len(y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking previous predictions ⚠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500002\n"
     ]
    }
   ],
   "source": [
    "y_prev_predicted = pd.read_csv('./../data/texts/colombian_valid_tweets_subject_predictions_bert_wwm.csv')\n",
    "print(len(y_prev_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking previous predictions\n",
    "with alive_bar(len(y_prev_predicted), force_tty = True) as bar:\n",
    "  print(\"Checking tweets already predicted\")\n",
    "  y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "  for index,serie in y_prev_predicted.iterrows():\n",
    "    if y_in.loc[index]['Id'] != y_prev_predicted.loc[index]['Id'] :\n",
    "      y_prev_predicted.drop(range(index), inplace=True)\n",
    "      y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "      print(\"Error found on:\",index, \"deleted, please run again\")\n",
    "      break\n",
    "    bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in.drop(range(len(y_prev_predicted)), inplace=True)\n",
    "predictions = y_prev_predicted.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0: Starting to predict                                                                                               \n",
      "on 20000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 40000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 60000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 80000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 100000: Checkpoint saved, sleeping for 1 minute                                                                      \n",
      "on 120000: Checkpoint saved, sleeping for 1 minute                                                                      \n",
      "on 140000: Checkpoint saved, sleeping for 1 minute                                                                      \n",
      "on 160000: Checkpoint saved, sleeping for 1 minute                                                                      \n",
      "|████████████████████████████████████████| 164901/164901 [100%] in 2:26:45.2 (18.73/s)                                  \n",
      "Finished the predictions\n"
     ]
    }
   ],
   "source": [
    "with alive_bar(len(y_in), force_tty = True) as bar:\n",
    "  print(\"Starting to predict\")\n",
    "\n",
    "  for index,serie in y_in.iterrows():\n",
    "    try:\n",
    "      referred_to = pipe(serie['text'])[0]['label']\n",
    "    except Exception as r:\n",
    "      referred_to = \"ERROR\"\n",
    "    predictions.append({'Id':serie['Id'], 'text':serie['text'], 'date':serie['date'],\n",
    "                        'referred_to':referred_to})\n",
    "\n",
    "    if bar.current() % 20000 == 0 and bar.current() != 0: #export every n tweets → checkpoint\n",
    "      pd.DataFrame.from_dict(predictions).to_csv('./../data/texts/colombian_v alid_tweets_subject_predictions_bert_wwm.csv', index=False)\n",
    "      print(\"Checkpoint saved, sleeping for 1 minute\")\n",
    "      sleep(60)# sleep for 60 seconds to avoid my pc exploding\n",
    "      \n",
    "    bar()\n",
    "print(\"Finished the predictions\")\n",
    "pd.DataFrame.from_dict(predictions).to_csv('./../data/texts/colombian_valid_tweets_subject_predictions_bert_wwm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions - tone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer)\n",
    "from alive_progress import alive_bar\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
    "model_tunned = AutoModelForSequenceClassification.from_pretrained(\"test_trainer_tone/checkpoint-500/\", num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model_tunned, tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"veneco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in = pd.read_csv('./../data/colombian_valid_tweets_predictions.csv')\n",
    "print(len(y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking previous predictions ⚠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prev_predicted = pd.read_csv('./../data/colombian_valid_tweets_tone_predictions.csv')\n",
    "print(len(y_prev_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking previous predictions\n",
    "with alive_bar(len(y_prev_predicted), force_tty = True) as bar:\n",
    "  print(\"Checking tweets already predicted\")\n",
    "  y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "  for index,serie in y_prev_predicted.iterrows():\n",
    "    if y_in.loc[index]['Id'] != y_prev_predicted.loc[index]['Id'] :\n",
    "      y_prev_predicted.drop(range(index), inplace=True)\n",
    "      y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "      print(\"Error found on:\",index, \"deleted, please run again\")\n",
    "      break\n",
    "    bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in.drop(range(len(y_prev_predicted)), inplace=True)\n",
    "predictions = y_prev_predicted.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with alive_bar(len(y_in), force_tty = True) as bar:\n",
    "  print(\"Starting to predict\")\n",
    "\n",
    "  for index,serie in y_in.iterrows():\n",
    "    try:\n",
    "      tone_scale = pipe(serie['text'])[0]['label']\n",
    "    except Exception as r:\n",
    "      tone_scale = \"ERROR\"\n",
    "    predictions.append({'Id':serie['Id'], 'text':serie['text'], 'date':serie['date'],\n",
    "                        'referred_to':serie['referred_to'], 'tone_str':tone_scale})\n",
    "\n",
    "    if bar.current() % 20000 == 0 and bar.current() != 0: #export every n tweets → checkpoint\n",
    "      pd.DataFrame.from_dict(predictions).to_csv('./../data/colombian_valid_tweets_tone_predictions.csv', index=False)\n",
    "      print(\"Checkpoint saved, sleeping for 1 minute\")\n",
    "      sleep(60)# sleep for 60 seconds to avoid my pc exploding\n",
    "      \n",
    "    bar()\n",
    "print(\"Finished the predictions\")\n",
    "pd.DataFrame.from_dict(predictions).to_csv('./../data/colombian_valid_tweets_tone_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions - negativity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joseph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import (AutoModelForSequenceClassification, AutoTokenizer)\n",
    "from alive_progress import alive_bar\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cardiffnlp/twitter-roberta-base-2021-124m\"\n",
    "model_tunned = AutoModelForSequenceClassification.from_pretrained(\"test_trainer_negativity/\", num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.8630983233451843}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model_tunned, tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"veneco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {'LABEL_0':-3, 'LABEL_1':-2, 'LABEL_2':-1, 'ERROR':'ERROR'}\n",
    "tones_dict = {'LABEL_0':'negative', 'LABEL_1':'positive', 'LABEL_2':'neutral', 'ERROR':'ERROR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485921\n"
     ]
    }
   ],
   "source": [
    "y_in = pd.read_csv('./../data/colombian_valid_tweets_tone_predictions.csv')\n",
    "print(len(y_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking previous predictions ⚠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485921\n"
     ]
    }
   ],
   "source": [
    "y_prev_predicted = pd.read_csv('./../data/colombian_valid_tweets_negativity_predictions.csv')\n",
    "print(len(y_prev_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking previous predictions\n",
    "with alive_bar(len(y_prev_predicted), force_tty = True) as bar:\n",
    "  print(\"Checking tweets already predicted\")\n",
    "  y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "  for index,serie in y_prev_predicted.iterrows():\n",
    "    if y_in.loc[index]['Id'] != y_prev_predicted.loc[index]['Id'] :\n",
    "      y_prev_predicted.drop(range(index), inplace=True)\n",
    "      y_prev_predicted.reset_index(drop=True, inplace=True)\n",
    "      print(\"Error found on:\",index, \"deleted, please run again\")\n",
    "      break\n",
    "    bar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_in.drop(range(len(y_prev_predicted)), inplace=True)\n",
    "predictions = y_prev_predicted.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict ✔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0: Starting to predict                                                                                               \n",
      "on 20000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 40000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 60000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 80000: Checkpoint saved, sleeping for 1 minute                                                                       \n",
      "on 100000: Checkpoint saved, sleeping for 1 minute                                                                      \n",
      "|████████████████████████████████████████✗︎ (!) 115537/115536 [100%] in 1:46:30.3 (18.08/s)                              \n",
      "Finished the predictions\n"
     ]
    }
   ],
   "source": [
    "with alive_bar(len(y_in)-1, force_tty = True) as bar:\n",
    "  print(\"Starting to predict\")\n",
    "\n",
    "  for index,serie in y_in.iterrows():\n",
    "    if serie['tone_str'] == 'LABEL_0':\n",
    "      try:\n",
    "        tone_scale = labels_dict[pipe(serie['text'])[0]['label']]\n",
    "      except:\n",
    "        tone_scale = \"ERROR\"\n",
    "    else:\n",
    "      tone_scale = \"not_negative\"\n",
    "      \n",
    "    predictions.append({'Id':serie['Id'], 'text':serie['text'], 'date':serie['date'],\n",
    "                          'referred_to':serie['referred_to'], 'tone_str':tones_dict[serie['tone_str']],\n",
    "                          'negativity':tone_scale})\n",
    "\n",
    "\n",
    "    if bar.current() % 20000 == 0 and bar.current() != 0: #export every n tweets → checkpoint\n",
    "      pd.DataFrame.from_dict(predictions).to_csv('./../data/colombian_valid_tweets_negativity_predictions.csv', index=False)\n",
    "      print(\"Checkpoint saved, sleeping for 1 minute\")\n",
    "      sleep(60)# sleep for 60 seconds to avoid my pc exploding\n",
    "      \n",
    "    bar()\n",
    "print(\"Finished the predictions\")\n",
    "pd.DataFrame.from_dict(predictions).to_csv('./../data/colombian_valid_tweets_negativity_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "954a6f92c48fca38f992f305027673bb9dc1ac69d50a77c523a6d9c197dc0ab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
